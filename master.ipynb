{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "honey-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-plastic",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "-Import the datasets. Still need the extra dataset. Includes triggers up to dec. 21\n",
    "\n",
    "-Create algorithm that searches for matches that are +/- 10 second apart and remove the rest (maybe two seconds)\n",
    "\n",
    "-First match found at 2018, 7, 11, 17, 2, 4\n",
    "\n",
    "-Do spectral analysis on the data (counts/bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-steal",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "lucky-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing and redefining the dataframes\n",
    "#Not loading the trigger list for 2021 yet\n",
    "\n",
    "ipn_data = pd.read_csv(\"trigIPN.csv\", sep=\"|\")\n",
    "ipn = pd.DataFrame(ipn_data)\n",
    "ipn.drop(columns= ['Unnamed: 0', 'Unnamed: 2'], axis=1, inplace=True) #dropping unwanted columns\n",
    "ipn.rename(columns={ipn.columns[0]:\"time\"}, inplace = True)\n",
    "\n",
    "trigB_data = pd.read_csv(\"./ASIM/trigB.txt\", sep = \"\\s+|\\t+|\\s+\\t+|\\t+\\s+\", engine=\"python\")\n",
    "trigB = pd.DataFrame(trigB_data)\n",
    "trigB.drop(columns=[\"######\"], inplace=True) #dropping unwanted columns\n",
    "trigB.rename(columns={\"yyyy-MMM-dd\":\"date\",\"HH:mm:ss.SSSSSS\": \"time\", \"Corr\":\"corr\"}, inplace=True) #renaming columns\n",
    "\n",
    "#trigB_21_data = pd.read_csv(\"./ASIM/trigB_2021.txt\", sep = \"\\s+|\\t+|\\s+\\t+|\\t+\\s+\", engine=\"python\")\n",
    "#trigB_21 = pd.DataFrame(trigB_21_data)\n",
    "#trigB_21.drop(columns=[\"######\"], inplace=True)\n",
    "#trigB_21.rename(columns={\"yyyy-MMM-dd\":\"date\",\"HH:mm:ss.SSSSSS\": \"time\" }, inplace=True)\n",
    "\n",
    "#trigC_data = pd.read_csv(\"./ASIM/trigC.txt\", sep = \"\\s+|\\t+|\\s+\\t+|\\t+\\s+\", engine=\"python\")\n",
    "#trigC = pd.DataFrame(trigC_data)\n",
    "#trigC.drop(columns=[\"######\"], inplace=True)\n",
    "#trigC.rename(columns={\"yyyy-MMM-dd\":\"date\",\"HH:mm:ss.SSSSSS\": \"time\" ,\"Corr\":\"corr\"}, inplace=True)\n",
    "\n",
    "#trigC_21_data = pd.read_csv(\"./ASIM/trigC_2021.txt\", sep = \"\\s+|\\t+|\\s+\\t+|\\t+\\s+\", engine=\"python\")\n",
    "#trigC_21 = pd.DataFrame(trigC_21_data)\n",
    "#trigC_21.drop(columns=[\"######\"], inplace=True)\n",
    "#trigC_21.rename(columns={\"yyyy-MMM-dd\":\"date\",\"HH:mm:ss.SSSSSS\": \"time\" }, inplace=True)\n",
    "\n",
    "#trigM_data = pd.read_csv(\"./ASIM/trigM.txt\", sep = \"\\s+|\\t+|\\s+\\t+|\\t+\\s+\", engine=\"python\")\n",
    "#trigM = pd.DataFrame(trigM_data)\n",
    "#trigM.drop(columns=[\"######\"], inplace=True)\n",
    "#trigM.rename(columns={\"yyyy-MMM-dd\":\"date\",\"HH:mm:ss.SSSSSS\": \"time\", \"Corr\":\"corr\" }, inplace=True)\n",
    "\n",
    "#trigM_21_data = pd.read_csv(\"./ASIM/trigM_2021.txt\", sep = \"\\s+|\\t+|\\s+\\t+|\\t+\\s+\", engine=\"python\")\n",
    "#trigM_21 = pd.DataFrame(trigM_21_data)\n",
    "#trigM_21.drop(columns=[\"######\"], inplace=True)\n",
    "#trigM_21.rename(columns={\"yyyy-MMM-dd\":\"date\",\"HH:mm:ss.SSSSSS\": \"time\" }, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-liquid",
   "metadata": {},
   "source": [
    "### Importing supplementary IPN triggers \n",
    "Latest ASIM trigger: 2021, 3, 20, 22, 51, 59\n",
    "\n",
    "Latest IPN trigger: 2021, 6, 27, 19, 31, 37 --> Extending this until the end of the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-maldives",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "dynamic-municipality",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#IPN datetime list\n",
    "ipn_dt_temp = []\n",
    "ipn_dict = ipn.to_dict(\"records\")\n",
    "for row in ipn_dict:\n",
    "    datetime_str = row[\"time\"]\n",
    "    datetime_obj = datetime.strptime(datetime_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "    ipn_dt_temp.append(datetime_obj)\n",
    "    \n",
    "ipn_dt = np.asarray(ipn_dt_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-hawaii",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "invalid-bracelet",
   "metadata": {},
   "source": [
    "## Vectorization and ASIM datetime correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "turkish-radical",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Function for correcting date and time in ASIM data. Returning matrix that contains datetime objects\n",
    "# Method for correcting time\n",
    "# 1. Retrive the time from time column\n",
    "# 2. Isolate the microsecond time from that and cast it to an int\n",
    "# 3. Retrive the correction time from Corr column and cast it to an int\n",
    "# 4. Subtract correction time from time and cast it to an string\n",
    "# 5. Insert the corrected time\n",
    "\n",
    "# PROBLEM: ONLY ONE DATETIME IS ADDED\n",
    "\n",
    "def corr_dt(dfs):  # Correcting times from ASIM data\n",
    "\n",
    "    \"\"\"   This function corrects the time from ASIM data.\n",
    "    The correction is done by subtracting the correction from the original time.\n",
    "    The correction is given as a string.\n",
    "    The function takes a list of dataframes as input.\n",
    "    The function returns a list of arrays containing the corrected datetime objects.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dfs : list of dataframes\n",
    "        The dataframes containing the data.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    trig_dt : list of arrays\n",
    "        The corrected datetime objects.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If the lists are not the same length.\n",
    "    \"\"\"\n",
    "    trig_dt = []\n",
    "    \n",
    "    for df in dfs:\n",
    "        temp_dt = []\n",
    "        # Vectorization of columns\n",
    "        date = df[\"date\"].values  # date given as string.\n",
    "        time = df[\"time\"].values  # time given as string\n",
    "        corr = df[\"corr\"].values  # correction given as string\n",
    "        try:\n",
    "            if len(date) and len(time) != len(corr):\n",
    "                raise ValueError\n",
    "        except:\n",
    "            raise ValueError(\"Lists are not the same length\")\n",
    "        else:\n",
    "            for i in np.arange(0, len(corr)):  # Iterating over the vectors\n",
    "                if corr[i] == \"--------\":  # No correction needed. Appending the datetime object\n",
    "                    date_str = date[i]\n",
    "                    time_str = time[i]\n",
    "                    org_dt = datetime.strptime(\n",
    "                        date_str + \" \" + time_str, \"%Y-%b-%d %H:%M:%S.%f\")\n",
    "                    temp_dt.append(org_dt)\n",
    "                    \n",
    "                elif corr[i][0] == \"-\":  # If it's a \"-\" in front; correction is added\n",
    "                    # formatting the datetime object\n",
    "                    date_str = date[i]\n",
    "                    time_str = time[i]\n",
    "                    org_dt = datetime.strptime(\n",
    "                        date_str + \" \" + time_str, \"%Y-%b-%d %H:%M:%S.%f\")  # Original datetime\n",
    "\n",
    "                    micro_corr = int(corr[0][1:])\n",
    "\n",
    "                    # new corrected datetime. Timedelta ccounts for changes in seconds also\n",
    "                    new_dt = org_dt + timedelta(microseconds=micro_corr)\n",
    "                    temp_dt.append(new_dt)\n",
    "                else:\n",
    "                    date_str = date[i]\n",
    "                    time_str = time[i]\n",
    "                    org_dt = datetime.strptime(\n",
    "                        date_str + \" \" + time_str, \"%Y-%b-%d %H:%M:%S.%f\")  # Original datetime\n",
    "\n",
    "                    micro_corr = int(corr[0][1:])\n",
    "\n",
    "                    # new corrected datetime. Timedelta ccounts for changes in seconds also\n",
    "                    new_dt = org_dt - timedelta(microseconds=micro_corr)\n",
    "                    temp_dt.append(new_dt)\n",
    "                    \n",
    "            trig_dt.append(temp_dt)\n",
    "\n",
    "    trig_dt = np.array(trig_dt)\n",
    "    return trig_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "theoretical-reducing",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Callig corr_dt with a list containing the dataframes from ASIM\n",
    "trig_dt = corr_dt([trigB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-basin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-contents",
   "metadata": {},
   "source": [
    "## Algorithm for match between ASIM and IPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "thick-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most compact algorithm for searching using np.where()\n",
    "#Storing matches in the match list. Stored as a tuple containing (datetime IPN, index trig_B)\n",
    "\n",
    "# TODO: wrap a function around it so it can take in several triggers (trigB,trigC etc..)\n",
    "matches = []\n",
    "\n",
    "for i in ipn_dt:\n",
    "    #Searching for matches that are +/- 10 seconds from the IPN trigger\n",
    "    mask = np.where((i-timedelta(seconds=10) <= trig_dt) & (trig_dt <= i + timedelta(seconds=10)))\n",
    "    if mask[1].size == 0:\n",
    "        continue\n",
    "    else:\n",
    "        matches.append((i,mask[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-slide",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "thousand-addiction",
   "metadata": {},
   "source": [
    "### Graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crude way of searching for a match\n",
    "#Extracting year,month,day,hour,minute from the ipn and trig array. Narrowing the search!\n",
    "def extract_datetime(dt_object):\n",
    "    year = dt_object.year\n",
    "    month = dt_object.month\n",
    "    day = dt_object.day\n",
    "    hour = dt_object.hour\n",
    "    minute = dt_object.minute\n",
    "    return year,month,day,hour,minute\n",
    "\n",
    "# Retriving datetimeobjects that fits the criteria; same year,month,day,hour,minute\n",
    "#Make a function out of this one\n",
    "temp_list = []\n",
    "#def narrowing_search(ipn,trigger)\n",
    "for i in ipn_dt:\n",
    "    year,month,day,hour,minute = extract_datetime(i)\n",
    "    for row in trig_dt[0]:\n",
    "        if row.year == year and row.month == month and row.day == day and row.hour == hour and row.minute == minute:\n",
    "            temp_list.append(row)\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "minute_match = np.array(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-catholic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-loading",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
