{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "contemporary-sullivan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-plastic",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "#### -Import the datasets. \n",
    "#### -Create algorithm that searches for matches that are +/- 10 second apart and remove the rest (maybe two seconds)\n",
    "#### -Do spectral analysis on the data (counts/bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verified-steal",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing and redefining the dataframes\n",
    "#Not loading the trigger list for 2021 yet\n",
    "\n",
    "ipn_data = pd.read_csv(\"trigIPN.csv\", sep=\"|\")\n",
    "ipn = pd.DataFrame(ipn_data)\n",
    "ipn.drop(columns= ['Unnamed: 0', 'Unnamed: 2'], axis=1, inplace=True) #dropping unwanted columns\n",
    "ipn.rename(columns={ipn.columns[0]:\"time\"}, inplace = True)\n",
    "\n",
    "trigB_data = pd.read_csv(\"./ASIM/trigB.txt\", sep = \"\\s+|\\t+|\\s+\\t+|\\t+\\s+\", engine=\"python\")\n",
    "trigB = pd.DataFrame(trigB_data)\n",
    "trigB.drop(columns=[\"######\"], inplace=True) #dropping unwanted columns\n",
    "trigB.rename(columns={\"yyyy-MMM-dd\":\"date\",\"HH:mm:ss.SSSSSS\": \"time\", \"Corr\":\"corr\"}, inplace=True) #renaming columns\n",
    "\n",
    "#trigB_21_data = pd.read_csv(\"./ASIM/trigB_2021.txt\", sep = \"\\s+|\\t+|\\s+\\t+|\\t+\\s+\", engine=\"python\")\n",
    "#trigB_21 = pd.DataFrame(trigB_21_data)\n",
    "#trigB_21.drop(columns=[\"######\"], inplace=True)\n",
    "#trigB_21.rename(columns={\"yyyy-MMM-dd\":\"date\",\"HH:mm:ss.SSSSSS\": \"time\" }, inplace=True)\n",
    "\n",
    "#trigC_data = pd.read_csv(\"./ASIM/trigC.txt\", sep = \"\\s+|\\t+|\\s+\\t+|\\t+\\s+\", engine=\"python\")\n",
    "#trigC = pd.DataFrame(trigC_data)\n",
    "#trigC.drop(columns=[\"######\"], inplace=True)\n",
    "#trigC.rename(columns={\"yyyy-MMM-dd\":\"date\",\"HH:mm:ss.SSSSSS\": \"time\" ,\"Corr\":\"corr\"}, inplace=True)\n",
    "\n",
    "#trigC_21_data = pd.read_csv(\"./ASIM/trigC_2021.txt\", sep = \"\\s+|\\t+|\\s+\\t+|\\t+\\s+\", engine=\"python\")\n",
    "#trigC_21 = pd.DataFrame(trigC_21_data)\n",
    "#trigC_21.drop(columns=[\"######\"], inplace=True)\n",
    "#trigC_21.rename(columns={\"yyyy-MMM-dd\":\"date\",\"HH:mm:ss.SSSSSS\": \"time\" }, inplace=True)\n",
    "\n",
    "#trigM_data = pd.read_csv(\"./ASIM/trigM.txt\", sep = \"\\s+|\\t+|\\s+\\t+|\\t+\\s+\", engine=\"python\")\n",
    "#trigM = pd.DataFrame(trigM_data)\n",
    "#trigM.drop(columns=[\"######\"], inplace=True)\n",
    "#trigM.rename(columns={\"yyyy-MMM-dd\":\"date\",\"HH:mm:ss.SSSSSS\": \"time\", \"Corr\":\"corr\" }, inplace=True)\n",
    "\n",
    "#trigM_21_data = pd.read_csv(\"./ASIM/trigM_2021.txt\", sep = \"\\s+|\\t+|\\s+\\t+|\\t+\\s+\", engine=\"python\")\n",
    "#trigM_21 = pd.DataFrame(trigM_21_data)\n",
    "#trigM_21.drop(columns=[\"######\"], inplace=True)\n",
    "#trigM_21.rename(columns={\"yyyy-MMM-dd\":\"date\",\"HH:mm:ss.SSSSSS\": \"time\" }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-municipality",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#IPN datetime list\n",
    "ipn_dt_temp = []\n",
    "ipn_dict = ipn.to_dict(\"records\")\n",
    "for row in ipn_dict:\n",
    "    datetime_str = row[\"time\"]\n",
    "    datetime_obj = datetime.strptime(datetime_str, \"%Y-%m-%d %H:%M:%S\")\n",
    "    ipn_dt_temp.append(datetime_obj)\n",
    "    \n",
    "ipn_dt = np.asarray(ipn_dt_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-bracelet",
   "metadata": {},
   "source": [
    "## Vectorization and ASIM datetime correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-radical",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Function for correcting date and time in ASIM data. Returning matrix that contains datetime objects\n",
    "# Method for correcting time\n",
    "# 1. Retrive the time from time column\n",
    "# 2. Isolate the microsecond time from that and cast it to an int\n",
    "# 3. Retrive the correction time from Corr column and cast it to an int\n",
    "# 4. Subtract correction time from time and cast it to an string\n",
    "# 5. Insert the corrected time\n",
    "\n",
    "# PROBLEM: ONLY ONE DATETIME IS ADDED\n",
    "\n",
    "def corr_dt(dfs):  # Correcting times from ASIM data\n",
    "\n",
    "    \"\"\"   This function corrects the time from ASIM data.\n",
    "    The correction is done by subtracting the correction from the original time.\n",
    "    The correction is given as a string.\n",
    "    The function takes a list of dataframes as input.\n",
    "    The function returns a list of arrays containing the corrected datetime objects.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dfs : list of dataframes\n",
    "        The dataframes containing the data.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    trig_dt : list of arrays\n",
    "        The corrected datetime objects.\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If the lists are not the same length.\n",
    "    \"\"\"\n",
    "    trig_dt = []\n",
    "    \n",
    "    for df in dfs:\n",
    "        temp_dt = []\n",
    "        # Vectorization of columns\n",
    "        date = df[\"date\"].values  # date given as string.\n",
    "        time = df[\"time\"].values  # time given as string\n",
    "        corr = df[\"corr\"].values  # correction given as string\n",
    "        try:\n",
    "            if len(date) and len(time) != len(corr):\n",
    "                raise ValueError\n",
    "        except:\n",
    "            raise ValueError(\"Lists are not the same length\")\n",
    "        else:\n",
    "            for i in np.arange(0, len(corr)):  # Iterating over the vectors\n",
    "                if corr[i] == \"--------\":  # No correction needed. Appending the datetime object\n",
    "                    date_str = date[i]\n",
    "                    time_str = time[i]\n",
    "                    org_dt = datetime.strptime(\n",
    "                        date_str + \" \" + time_str, \"%Y-%b-%d %H:%M:%S.%f\")\n",
    "                    temp_dt.append(org_dt)\n",
    "                    \n",
    "                elif corr[i][0] == \"-\":  # If it's a \"-\" in front; correction is added\n",
    "                    # formatting the datetime object\n",
    "                    date_str = date[i]\n",
    "                    time_str = time[i]\n",
    "                    org_dt = datetime.strptime(\n",
    "                        date_str + \" \" + time_str, \"%Y-%b-%d %H:%M:%S.%f\")  # Original datetime\n",
    "\n",
    "                    micro_corr = int(corr[0][1:])\n",
    "\n",
    "                    # new corrected datetime. Timedelta ccounts for changes in seconds also\n",
    "                    new_dt = org_dt + timedelta(microseconds=micro_corr)\n",
    "                    temp_dt.append(new_dt)\n",
    "                else:\n",
    "                    date_str = date[i]\n",
    "                    time_str = time[i]\n",
    "                    org_dt = datetime.strptime(\n",
    "                        date_str + \" \" + time_str, \"%Y-%b-%d %H:%M:%S.%f\")  # Original datetime\n",
    "\n",
    "                    micro_corr = int(corr[0][1:])\n",
    "\n",
    "                    # new corrected datetime. Timedelta ccounts for changes in seconds also\n",
    "                    new_dt = org_dt - timedelta(microseconds=micro_corr)\n",
    "                    temp_dt.append(new_dt)\n",
    "                    \n",
    "            trig_dt.append(temp_dt)\n",
    "\n",
    "    trig_dt = np.asarray(trig_dt)\n",
    "    return trig_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-reducing",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Callig corr_dt with a list containing the dataframes from ASIM\n",
    "trig_dt = corr_dt([trigB])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-contents",
   "metadata": {},
   "source": [
    "## Algorithm for match between ASIM and IPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-arbitration",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Storing matches in a dictionary\n",
    "# Need to speed up this algorithm. Because it's swallowing too much RAM\n",
    "\n",
    "\n",
    "\"\"\"def search(ipn_dt, trig_dt, diff = 10):\n",
    "    \"\"\"This function takes in two arrays of datetime objects: one for IPN triggers and one for the triggers of choice.\n",
    "    It returns a dictionary of lists of tuples. The dictionary contains the indices of the matching triggers for each\n",
    "    type of trigger. The tuples contain the indices of the IPN and the trigger of choice.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ipn_dt : list of datetime objects\n",
    "        The list of IPN triggers\n",
    "    trig_dt : list of datetime objects: trig_dt = [trigB [<datetime object ...>], trigC[<datetime object ..>] ...]\n",
    "        The list of triggers of choice\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matches_dict : dictionary\n",
    "        A dictionary of lists of tuples. The dictionary contains the indices of the matching triggers for each\n",
    "        type of trigger. The tuples contain the indices of the IPN and the trigger of choice.\"\"\"\n",
    "    \n",
    "    \n",
    "    matches_dict = {\"trigB\": [], \"trigC\": [], \"trigM\": []}\n",
    "    #Maybe use list comprehention: newlist = [x for x in fruits if \"a\" in x]\n",
    "    \n",
    "    for trig, col in enumerate(trig_dt):\n",
    "\n",
    "        for index_trig, trig_time in enumerate(col):\n",
    "            try:\n",
    "                if trig == 0: #Maybe this can be modified?\n",
    "                    for index_ipn, ipn_time in enumerate(ipn_dt):\n",
    "                        t_delta = ipn_time - trig_time\n",
    "                        if t_delta.total_seconds() <= diff:\n",
    "                            matches_dict[\"trigB\"].append((index_ipn, index_trig))\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                elif trig == 1:\n",
    "                    for index_ipn, ipn_time in enumerate(ipn_dt):\n",
    "                        t_delta = ipn_time - trig_time\n",
    "                        if t_delta.total_seconds() <= diff:\n",
    "                            matches_dict[\"trigC\"].append((index_ipn, index_trig))\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                elif trig == 2:\n",
    "                    for index_ipn, ipn_time in enumerate(ipn_dt):\n",
    "                        t_delta = ipn_time - trig_time\n",
    "                        if t_delta.total_seconds() <= diff:\n",
    "                            matches_dict[\"trigM\"].append((index_ipn, index_trig))\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "            except ValueError:\n",
    "                print(\"Length of input trigger list is not correct\")\n",
    "    return matches_dict\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-demand",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_dict = search(ipn_dt,trig_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-conclusion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "thousand-addiction",
   "metadata": {},
   "source": [
    "### Graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-paris",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-catholic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-loading",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
